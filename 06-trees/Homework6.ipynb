{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "936f5d65-68c6-4750-ab7e-2716be826e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cf78389-cca3-4e8c-96db-67d9ea9724a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/alexeygrigorev/datasets/raw/refs/heads/master/jamb_exam_results.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Step 1: Preparing the dataset\n",
    "# lowercase column names and replace spaces with underscores\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Drop the 'student_id' column\n",
    "df = df.drop(columns=['student_id'])\n",
    "\n",
    "# fill missing values with zeros\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ccd9adf-783b-4d10-b632-092a7ed28680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train/Validation/Test Split (60%/20%/20%)\n",
    "df_train, df_temp = train_test_split(df, test_size=0.4, random_state=1)\n",
    "df_val, df_test = train_test_split(df_temp, test_size=0.5, random_state=1)\n",
    "\n",
    "# separate the target variable\n",
    "y_train = df_train['jamb_score'].values\n",
    "y_val = df_val['jamb_score'].values\n",
    "y_test = df_test['jamb_score'].values\n",
    "\n",
    "# drop target variable from features\n",
    "df_train = df_train.drop(columns=['jamb_score'])\n",
    "df_val = df_val.drop(columns=['jamb_score'])\n",
    "df_test = df_test.drop(columns=['jamb_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cd89ae-dfa2-49e9-8782-55914c51c7df",
   "metadata": {},
   "source": [
    "Question 1: Which feature is used for splitting the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb6ae9ea-a524-47af-8178-abaf2ff75d5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'study_hours_per_week'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Vectorize using DictVectorizer\n",
    "dv = DictVectorizer(sparse=True)\n",
    "\n",
    "X_train = dv.fit_transform(df_train.to_dict(orient='records'))\n",
    "X_val = dv.transform(df_val.to_dict(orient='records'))\n",
    "X_test = dv.transform(df_test.to_dict(orient='records'))\n",
    "\n",
    "# Step 4: Train Decision Tree Regressor with max_depth=1\n",
    "dt = DecisionTreeRegressor(max_depth=1, random_state=1)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# feature used for splitting\n",
    "split_feature = dv.feature_names_[dt.tree_.feature[0]]\n",
    "split_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a881e0-b9a7-4afb-80f7-bd3827449a6a",
   "metadata": {},
   "source": [
    "Question 2: What's the RMSE of this model on the validation data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e7bb5f7-cd41-4389-a595-b5637b22838f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.157758977963624"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# train a random forest regressor with specified parameters\n",
    "rf = RandomForestRegressor(n_estimators=10, random_state=1, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# predict on the validation set\n",
    "y_pred_val = rf.predict(X_val)\n",
    "\n",
    "# calculate RMSE for the validation set\n",
    "rmse_val = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "rmse_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6fc051-f792-4553-9910-99787447b1db",
   "metadata": {},
   "source": [
    "Question 3: After which value of n_estimators does RMSE stop improving?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e72fc6f0-5422-4dff-b3a4-7c7cfdc2a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # range of n_estimators to test, using step of 5 to capture the provided options exactly\n",
    "# n_estimators_values = range(10, 201, 5)\n",
    "# rmse_values = []\n",
    "\n",
    "# # RandomForestRegressor for each n_estimators value and calculate RMSE on validation set\n",
    "# for n in n_estimators_values:\n",
    "#     rf = RandomForestRegressor(n_estimators=n, random_state=1, n_jobs=-1)\n",
    "#     rf.fit(X_train, y_train)\n",
    "#     y_pred_val = rf.predict(X_val)\n",
    "#     rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "#     rmse_values.append(round(rmse, 3))  # Round RMSE to 3 decimal places for consistency\n",
    "\n",
    "# # find the closest value among the answers options where RMSE stops improving significantly\n",
    "# options = [10, 25, 80, 200]\n",
    "\n",
    "# # locate the stabilization point based on the options\n",
    "# best_option = None\n",
    "# for i in range(1, len(rmse_values)):\n",
    "#     # Check if the RMSE has stopped improving significantly (difference below threshold)\n",
    "#     if abs(rmse_values[i] - rmse_values[i - 1]) < 0.001:\n",
    "#         # Find the closest n_estimators from the options list\n",
    "#         closest_option = min(options, key=lambda x: abs(x - n_estimators_values[i]))\n",
    "#         best_option = closest_option\n",
    "#         break\n",
    "\n",
    "# rmse_values, best_option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c988f3f-52ba-4543-9ab3-c360dba985d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([43.158,\n",
       "  42.168,\n",
       "  41.79,\n",
       "  41.721,\n",
       "  41.556,\n",
       "  41.33,\n",
       "  41.076,\n",
       "  40.927,\n",
       "  40.957,\n",
       "  40.892,\n",
       "  40.774,\n",
       "  40.665,\n",
       "  40.588,\n",
       "  40.555,\n",
       "  40.503,\n",
       "  40.475,\n",
       "  40.435,\n",
       "  40.422,\n",
       "  40.365,\n",
       "  40.351,\n",
       "  40.348,\n",
       "  40.329,\n",
       "  40.302,\n",
       "  40.275,\n",
       "  40.286,\n",
       "  40.278,\n",
       "  40.263,\n",
       "  40.242,\n",
       "  40.254,\n",
       "  40.216,\n",
       "  40.2,\n",
       "  40.196,\n",
       "  40.187,\n",
       "  40.147,\n",
       "  40.136,\n",
       "  40.136,\n",
       "  40.152,\n",
       "  40.166,\n",
       "  40.138],\n",
       " 185)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define range for n_estimators with a step of 5\n",
    "n_estimators_values = range(10, 201, 5)\n",
    "rmse_values = []\n",
    "\n",
    "# Calculate RMSE for each n_estimators value on the validation set\n",
    "for n in n_estimators_values:\n",
    "    rf = RandomForestRegressor(n_estimators=n, random_state=1, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_val = rf.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "    rmse_values.append(round(rmse, 3))  # Round RMSE to 3 decimal places for consistency\n",
    "\n",
    "# Identify the stabilization point based on minimal improvement\n",
    "stabilization_point = None\n",
    "for i in range(1, len(rmse_values)):\n",
    "    if abs(rmse_values[i] - rmse_values[i - 1]) < 0.001:\n",
    "        stabilization_point = n_estimators_values[i]\n",
    "        break\n",
    "\n",
    "rmse_values, stabilization_point\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e91d19-4a08-4d33-939d-f4746c630797",
   "metadata": {},
   "source": [
    "Answer6: 200 is the closest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e5dde4-891b-4ce2-a8b7-a34cea7434f7",
   "metadata": {},
   "source": [
    "Question 4: What's the best max_depth, using the mean RMSE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e123a3e-bbc6-4004-bae9-d7a9a6d083b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({10: 40.13800364122155,\n",
       "  15: 40.64396557212339,\n",
       "  20: 40.60981968462706,\n",
       "  25: 40.687581741749185},\n",
       " 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# different values of max_depth and n_estimators to find the best max_depth based on mean RMSE\n",
    "\n",
    "# define the parameters to test\n",
    "max_depth_values = [10, 15, 20, 25]\n",
    "n_estimators_values = range(10, 201, 10)\n",
    "mean_rmse_results = {}\n",
    "\n",
    "# loop over each max_depth\n",
    "for max_depth in max_depth_values:\n",
    "    rmse_list = []  # To store RMSE values for each n_estimators value with the current max_depth\n",
    "    \n",
    "    for n in n_estimators_values:\n",
    "        rf = RandomForestRegressor(n_estimators=n, max_depth=max_depth, random_state=1, n_jobs=-1)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred_val = rf.predict(X_val)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "        rmse_list.append(rmse)\n",
    "    \n",
    "    # mean RMSE for the current max_depth\n",
    "    mean_rmse_results[max_depth] = np.mean(rmse_list)\n",
    "\n",
    "# best max_depth with the lowest mean RMSE\n",
    "best_max_depth = min(mean_rmse_results, key=mean_rmse_results.get)\n",
    "mean_rmse_results, best_max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd40a253-1502-41fe-a6cd-caa54bfef6a2",
   "metadata": {},
   "source": [
    "Answer: best max_depth is for mean RSE 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53d0d7a9-ba6d-4c80-ab1d-ba1f287468a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'study_hours_per_week': 0.25407520246568593,\n",
       "  'attendance_rate': 0.15213485818850264,\n",
       "  'distance_to_school': 0.13576097373953083,\n",
       "  'teacher_quality': 0.08173314573636019},\n",
       " 'study_hours_per_week')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestRegressor with the specified parameters\n",
    "rf = RandomForestRegressor(n_estimators=10, max_depth=20, random_state=1, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "# mapedp feature importances to feature names for easier interpretation\n",
    "feature_importance_dict = dict(zip(dv.feature_names_, feature_importances))\n",
    "\n",
    "# filter for the specified features and identify the most important one\n",
    "selected_features = [\"study_hours_per_week\", \"attendance_rate\", \"distance_to_school\", \"teacher_quality\"]\n",
    "important_features = {feature: feature_importance_dict[feature] for feature in selected_features if feature in feature_importance_dict}\n",
    "most_important_feature = max(important_features, key=important_features.get)\n",
    "\n",
    "important_features, most_important_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d97b43-dee0-4f35-8868-ac0ede9d75f1",
   "metadata": {},
   "source": [
    "Answer: study_hours_per_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26c8824e-0199-4d83-babd-22245b52ba40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/anaconda3/lib/python3.12/site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from xgboost) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80372036-5626-42b6-8848-ce3713cfec3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43.342905809394544, 40.8318750593964)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DMatrix for train and validation data\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "# Define parameters with eta = 0.3\n",
    "xgb_params_03 = {\n",
    "    'eta': 0.3,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "# parameters with eta = 0.1\n",
    "xgb_params_01 = xgb_params_03.copy()\n",
    "xgb_params_01['eta'] = 0.1\n",
    "\n",
    "# watchlist to evaluate performance on validation data\n",
    "watchlist = [(dtrain, 'train'), (dval, 'val')]\n",
    "\n",
    "# train with eta = 0.3\n",
    "model_03 = xgb.train(params=xgb_params_03, dtrain=dtrain, num_boost_round=100, evals=watchlist, verbose_eval=False)\n",
    "y_pred_val_03 = model_03.predict(dval)\n",
    "rmse_03 = np.sqrt(mean_squared_error(y_val, y_pred_val_03))\n",
    "\n",
    "# train with eta = 0.1\n",
    "model_01 = xgb.train(params=xgb_params_01, dtrain=dtrain, num_boost_round=100, evals=watchlist, verbose_eval=False)\n",
    "y_pred_val_01 = model_01.predict(dval)\n",
    "rmse_01 = np.sqrt(mean_squared_error(y_val, y_pred_val_01))\n",
    "\n",
    "# compare RMSE values\n",
    "rmse_03, rmse_01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375d6cb1-2e08-4a67-8fa7-21772f5f1c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
